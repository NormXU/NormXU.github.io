---
layout: post
title: "Dataset Cheatsheet"
tags: ["CheatSheet"]
excerpt_separator: <!--more-->
toc: true
---

<h3 class="no_toc"> TL; DR</h3>

- A dataset zoo for multi-modal language models

<!--more-->

<hr>

## Language Corpus

| name       | size                                                                                                                           | des                                                                                                                                                                         |
| ---------- | ------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| SlimPajama | [6B](https://huggingface.co/datasets/DKYoon/SlimPajama-6B) / [627 B](https://huggingface.co/datasets/cerebras/SlimPajama-627B) | has balanced domains； consisting of 82% web data (67% from
CommonCrawl and 15% from C4), 4.5% code (Github), 4.5% Wikipedia, 4.5% books, 2.5% Arxiv, and 2.0% StackExchange |

## Image-Text Pair

| name                                                                     | size | des                                                                                  |
| ------------------------------------------------------------------------ | ---- | ------------------------------------------------------------------------------------ |
| [COYO-700M](https://github.com/kakaobrain/coyo-dataset)                  |      | primarily highly aesthetic scenic photos                                             |
| LAION-2B                                                                 |      |                                                                                      |
| LAION-COCO                                                               | 600M | A subset of LAION-2B that is captioned by BLIP                                       |
| LAION-Aesthetics                                                         | 100M | A high-aesthetics image subset of LAION-5B                                           |
| [Conceptual Caption](https://ai.google.com/research/ConceptualCaptions/) | 3.3M | Raw descriptions are harvested from the web; Caption quality is not very satisfying. |

## Video-Text Pair

| name       | size                 | des                                                                              |
| ---------- | -------------------- | -------------------------------------------------------------------------------- |
| WebVid-10M | 10M, 52k video hours | video-text pairs scraped from the stock footage sites; it has a common watermark |

## SFT Dataset for Visual-Language Model

| name                                                                                                   | size | des                                                                                                              |
| ------------------------------------------------------------------------------------------------------ | ---- | ---------------------------------------------------------------------------------------------------------------- |
| [ShareGPT4V](https://sharegpt4v.github.io/)                                                            | 100k | high-quality captions from GPT4-Vision for instruction tuning                                                    |
| ShareGPT4v-PT                                                                                          | 1.2M | captioned by Share-Captioner, based on LLaVA-v1.5-7B                                                             |
| [Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT)                                          | 100k | 100k video-text instruction dataset                                                                              |
| [LLaVA Visual Instruct CC3M 595K](https://huggingface.co/datasets/liuhaotian/LLaVA-CC3M-Pretrain-595K) | 595K | a subset of CC-3M dataset, use to connect a frozen pretrained vision encoder to a frozen LLM (feature alignment) |

## Evaluation Dataset